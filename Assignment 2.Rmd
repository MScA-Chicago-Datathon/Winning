---
title: "Assignment 2"
author: "Arthur Yu, Hristina Hristova"
date: "4/14/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**1. Based on the properties of the exponential distribution function, show that:**

* If $Y$ is $Poisson(θ)$, then $E[Y]=VAR[Y]=θ$
  
  For Poisson distribution, 
  
  \begin{aligned}
        f(y; \theta) & = \frac{\theta^{y} e^{-\theta}}{y!} \\
                     & = exp[ln(\frac{\theta^{y} e^{-\theta}}{y!})] \\
                     & = exp(yln\theta - \theta - lny!)
  \end{aligned}
  
  $$So, a(y) = y, b(\theta) = ln\theta, c(\theta) = -\theta, d(y) = -lny!$$
  
  \begin{aligned}
        E[Y] & = - \dfrac{c'(\theta)}{b'(\theta)} \\
             & = - \dfrac{(-\theta)'}{(ln\theta)'} \\
             & = - \dfrac{-1}{\frac{1}{\theta}} \\
             & = \theta 
  \end{aligned}
  
  \begin{aligned}
        VAR[Y] & = \dfrac{b''(\theta) c'(\theta) - c''(\theta) b'(\theta)}{[b'(\theta)]^{3}} \\
               & = \dfrac{(ln\theta)''(-\theta)' - (-\theta)''(ln\theta)'}{[(ln\theta)']^3} \\
               & = \dfrac{-\frac{1}{\theta^2}(-1) - 0}{(\frac{1}{\theta})^3} \\
               & = \theta
  \end{aligned}
                
  $$So, E[Y]=VAR[Y]=θ$$

   
* If $Y$ is $N(\mu, \sigma^2)$, then $E[Y] = \mu$ and $VAR[Y] = \sigma^2$

  For Normal distribution, 
  
  \begin{aligned}
        f(y; \mu) & = \frac{1}{(2 \pi \sigma^{2})^{\frac{1}{2}}} e^{-\frac{1}{2\sigma^{2}}(y - \mu)^{2}} \\
                     & = exp[ln(\frac{1}{(2 \pi \sigma^{2})^{\frac{1}{2}}} e^{-\frac{1}{2\sigma^{2}}(y - \mu)^{2}})] \\
                     & = exp\left\{-\frac{y^{2}}{2\sigma^{2}}+\frac{y \mu}{\sigma^{2}}-\frac{\mu^{2}}{2\sigma^{2}}-\frac{1}{2}ln(2\pi\sigma^{2})\right\}
  \end{aligned}

   $$So, a(y) = y, b(\mu) = \dfrac{\mu}{\sigma^2}, c(\mu) = -\dfrac{\mu^2}{2\sigma^2} - \dfrac{1}{2}ln(2\pi\sigma^2), d(y) = -\dfrac{y^2}{2\sigma^2}$$
   
  \begin{aligned}
        E[Y] & = - \dfrac{c'(\mu)}{b'(\mu)} \\
             & = - \dfrac{(-\dfrac{\mu^2}{2\sigma^2} - \dfrac{1}{2}ln(2\pi\sigma^2))'}{(\dfrac{\mu}{\sigma^2})'} \\
             & = - \dfrac{-\frac{\mu}{\sigma^2}}{\frac{1}{\sigma^2}} \\
             & = \mu
  \end{aligned}
    
  \begin{aligned}
        VAR[Y] & = \dfrac{b''(\mu) c'(\mu) - c''(\mu) b'(\mu)}{[b'(\mu)]^{3}} \\
               & = \dfrac{(\dfrac{\mu}{\sigma^2})''(-\dfrac{\mu^2}{2\sigma^2} - \dfrac{1}{2}ln(2\pi\sigma^2))' - (-\dfrac{\mu^2}{2\sigma^2} - \dfrac{1}{2}ln(2\pi\sigma^2))''(\dfrac{\mu}{\sigma^2})'}{[(\dfrac{\mu}{\sigma^2})']^3} \\
               & = \dfrac{0 + \frac{1}{\sigma^2} \frac{1}{\sigma^2} }{(\frac{1}{\sigma^2})^3} \\
               & = \sigma^2
  \end{aligned}
    
    $$So, E[Y] = \mu and VAR[Y] = \sigma^2$$
    
    
* If $Y$ is $binomial(n, \pi)$, then $E(Y) = n\pi$ and $VAR[Y] = n\pi(1 − \pi)$

  For Binomial distribution,
  
  \begin{aligned}
        f(y; \pi) & = {n \choose y} \pi^{y} (1-\pi)^{n-y} \\
                  & = exp[ln({n \choose y} \pi^{y} (1-\pi)^{n-y})] \\
                  & = exp\{ y ln\frac{\pi}{1-\pi} + nln(1-\pi) + ln {n \choose y}\}
  \end{aligned}
 
  $$So, a(y) = y, b(\pi) = ln\dfrac{\pi}{1-\pi}, c(\pi) = nln(1 - \pi), d(y) = ln{n \choose y}$$
    
  \begin{aligned}
        E[Y] & = - \dfrac{c'(\pi)}{b'(\pi)} \\
             & = - \dfrac{(nln(1 - \pi))'}{(ln\dfrac{\pi}{1-\pi})'} \\
             & = - \dfrac{-\frac{n}{1-\pi}}{\frac{1}{(1-\pi)\pi}} \\
             & = n\pi
  \end{aligned}
    
  \begin{aligned}
        VAR[Y] & = \dfrac{b''(\pi) c'(\pi) - c''(\pi) b'(\pi)}{[b'(\pi)]^{3}} \\
               & = \dfrac{(ln\dfrac{\pi}{1-\pi})''(nln(1 - \pi))' - (nln(1 - \pi))''(ln\dfrac{\pi}{1-\pi})'}{[(ln\dfrac{\pi}{1-\pi})']^3} \\
               & = \dfrac{\frac{2\pi - 1}{\pi^2(1-\pi)^2}\frac{n}{\pi - 1} + \frac{n}{(1-\pi)^2}\frac{1}{(1-\pi)\pi}}{(\frac{1}{(1-\pi)\pi})^3} \\
               & = n\pi( 1- \pi)
  \end{aligned}        
    
    $$So, E(Y) = n\pi and VAR[Y] = n\pi(1 − \pi)$$

**2.Based on the R dataset in the Lab folder (1030.lecture-mle.RData), reproduce the results presented above for the Binomial distribution. Plot results, maximum likelihood estimates and R code must be submitted.**

```{r}
dataPath <- "/Users/doubao/Desktop/Course Work/Linear & Non-Linear"
load(paste(dataPath, "1020.lecture-mle.rdata", sep = "/"))
```

```{r}
n <- dta$binomial$n
y <- dta$binomial$y
pi <- 0.6
Mean <- n * pi
par(mfrow = c(1, 2))
plot(y, type = "l", col = "red")
abline(h = Mean)
hist(y)
abline(v = Mean, col = "red")
```

```{r}
l <- function(p, y = y){
  sum(log(choose(n, y))) + log(p) * sum(y) + log(1 - p) * sum(n - y)
}
dl <- function(p, y = y){
  1 / p * sum(y) - 1/(1 - p) * (sum(n) - sum(y))
}
```

```{r}
prob <- seq(0.05, 0.95, by = 0.01)
(p.hat <- sum(y) / sum(n))
loglike <- sapply(prob, l, y = y)
dloglike <- sapply(prob, dl, y = y)
par(mfrow = c(1, 2))
plot(prob, loglike, type = "l", col = "red")
abline(v = p.hat)
plot(prob, dloglike, type = "l", col = "red")
abline(v = p.hat)
```


**3.Based on the R dataset in the Lab folder (1030.lecture-mle.RData) reproduce the results presented above for the Poisson distribution. Plot results, maximum likelihood estimates and R code must be submitted.**

```{r}
y <- dta$poisson$y
n <- length(y)
par(mfrow=c(1,2))
lb = 3
plot(y, type = "h", col = "red")
abline(h = lb)
hist(y)
abline(v = lb, col = "red")
```

```{r}
l <- function(lambda, y = y){
  log(lambda) * sum(y) - n * lambda - sum(log(factorial(y)))
}
dl <- function(lambda, y = y){
  1 / lambda * sum(y) - n
}
```

```{r}
(lb.hat <- sum(y) / sum(n))
lbd <- seq(1, 10, by = 0.1)
loglike <- sapply(lbd, l, y = y)
dloglike <- sapply(lbd, dl, y = y)
par(mfrow = c(1, 2))
plot(lbd, loglike, type = "l", col = "red")
abline(v = lb.hat)
plot(lbd, dloglike, type = "l", col = "red")
abline(v = lb.hat)
```

